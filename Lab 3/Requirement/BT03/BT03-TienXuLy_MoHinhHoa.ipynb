{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# BT03: Tiền xử lý và mô hình hóa dữ liệu\n",
    "\n",
    "(Cập nhật 27/12/2020)\n",
    "\n",
    "Họ tên: ...\n",
    "\n",
    "MSSV: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Cách làm bài và nộp bài\n",
    "&#9889; Bạn lưu ý là mình sẽ dùng chương trình hỗ trợ chấm bài nên bạn cần phải tuân thủ chính xác qui định mà mình đặt ra, nếu không rõ thì hỏi, chứ không nên tự tiện làm theo ý của cá nhân.\n",
    "\n",
    "**Cách làm bài**\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này. Đầu tiên, bạn điền họ tên và MSSV vào phần đầu file ở bên trên. Trong file, bạn làm bài ở những chỗ có ghi là:\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "hoặc đối với những phần code không bắt buộc thì là:\n",
    "```python\n",
    "# YOUR CODE HERE (OPTION)\n",
    "```\n",
    "hoặc đối với markdown cell thì là:\n",
    "```markdown\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "Tất nhiên, khi làm thì bạn xóa dòng `raise NotImplementedError()` đi.\n",
    "Đối những phần yêu cầu code thì thường ở ngay phía dưới sẽ có một (hoặc một số) cell chứa các bộ test để giúp bạn biết đã code đúng hay chưa; nếu chạy cell này không có lỗi gì thì có nghĩa là qua được các bộ test. Trong một số trường hợp, các bộ test có thể sẽ không đầy đủ; nghĩa là, nếu không qua được test thì là code sai, nhưng nếu qua được test thì chưa chắc đã đúng.\n",
    "\n",
    "Trong khi làm bài, bạn có thể cho in ra màn hình, tạo thêm các cell để test. Nhưng khi nộp bài thì bạn xóa các cell mà bạn tự tạo, xóa hoặc comment các câu lệnh in ra màn hình. Bạn lưu ý <font color=red>không được tự tiện xóa các cell hay sửa code của Thầy</font> (trừ những chỗ được phép sửa như đã nói ở trên).\n",
    "\n",
    "Trong khi làm bài, thường xuyên `Ctrl + S` để lưu lại bài làm của bạn, tránh mất mát thông tin.\n",
    "\n",
    "\n",
    "*Nên nhớ mục tiêu chính ở đây là <font color=green>học, học một cách chân thật</font>. Bạn có thể thảo luận ý tưởng với bạn khác, nhưng <font color=green>code và bài làm phải là của bạn, dựa trên sự hiểu thật sự của bạn</font>. <font color=red>Nếu vi phạm thì sẽ bị 0 điểm cho toàn bộ môn học.</font>*\n",
    "\n",
    "**Cách nộp bài**\n",
    "\n",
    "Khi chấm bài, đầu tiên mình sẽ chọn `Kernel` - `Restart & Run All`, để restart và chạy tất cả các cell trong notebook của bạn; do đó, trước khi nộp bài, bạn nên chạy thử `Kernel` - `Restart & Run All` để đảm bảo mọi chuyện diễn ra đúng như mong đợi.\n",
    "\n",
    "Sau đó, bạn tạo thư mục nộp bài theo cấu trúc sau:\n",
    "- Thư mục `MSSV` (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`)\n",
    "    - File `BT03-TienXuLy_MoHinhHoa.ipynb` (không cần nộp các file khác)\n",
    "\n",
    "Cuối cùng, bạn nén thư mục `MSSV` này lại và nộp ở link trên moodle. <font color=red>Bạn lưu ý tuân thủ chính xác cấu trúc này.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # seaborn là thư viện được xây trên matplotlib, giúp việc visualization đỡ khổ hơn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram') # Để trực quan hóa pipeline\n",
    "\n",
    "# You can also import other things ...\n",
    "# YOUR CODE HERE (OPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Thu thập dữ liệu\n",
    "Bộ dữ liệu được sử dụng trong bài tập là bộ dữ liệu đã được thu thập sẵn cho [một cuộc thi trên Kaggle](https://www.kaggle.com/c/titanic); bộ dữ liệu này là về thông tin của các hành khách trên chuyến tàu Titanic mà đã bị chìm do đâm phải tảng băng trôi vào năm 1912 (chắc bạn cũng có biết). Ban đầu, mình định sử dụng bộ dữ liệu về giá nhà cho bài tập này (như mình có nói trên lớp); tuy nhiên, các bộ dữ liệu về giá nhà mà mình tìm được không có những đặc điểm mà mình muốn (mình muốn dữ liệu có giá trị thiếu, có các cột dạng chuỗi, ... để bạn có thể thực hành tiền xử lý các vấn đề này). Do đó, mình đã đổi sang bộ dữ liệu này (do mình không sử dụng bộ dữ liệu về giá nhà nữa nên cũng không còn yêu cầu tránh bộ dữ liệu này trong đồ án cuối kỳ).\n",
    "\n",
    "Cuộc thi trên Kaggle với bộ dữ liệu này là về mô hình hóa dữ liệu nên Kaggle đã tách sẵn tập huấn luyện và tập kiểm tra. Mình có đính kèm các file dữ liệu mà Kaggle cung cấp: \n",
    "- File \"train.csv\": tập huấn luyện\n",
    "- File \"test.csv\": tập kiểm tra (chỉ có input, dùng để submit kết quả dự đoán của mô hình sau cùng lên Kaggle)\n",
    "- File \"description.txt\": mô tả ý nghĩa của các cột"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Khám phá dữ liệu (đủ để có thể xác định câu hỏi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('train.csv', \n",
    "                      index_col=0) # Cho cột index là cột 0 (PassengerId)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dữ liệu có bao nhiêu dòng và bao nhiêu cột?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mỗi dòng có ý nghĩa gì? Có vấn đề các dòng có ý nghĩa khác nhau không?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quan sát sơ bộ dữ liệu ta thấy mỗi dòng chứa thông tin của một hành khách, và có vẻ không có vấn đề các dòng có ý nghĩa khác nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dữ liệu có các dòng bị lặp không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mỗi cột có ý nghĩa gì?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem file \"description.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('description.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khám phá dữ liệu đến đây là đã đủ để có thể đưa ra câu hỏi cần trả lời. Sau khi đưa ra câu hỏi cần trả lời thì ta sẽ tiến hành ngay bước tiền xử lý là tách ra tập validation và tập kiểm tra (ở bài tập này thì chỉ tách tập validation, vì tập kiểm tra đã được Kaggle tách ra trước đó). Sau đó, ta có thể tiếp tục khám phá trên *tập huấn luyện* (tập mà đã tách ra tập validation và tập kiểm tra) để hiểu hơn về dữ liệu.\n",
    "\n",
    "Sở dĩ ta cần *tách sớm tập validation và tập kiểm tra* vì 2 tập này (đặc biệt là tập kiểm tra) cần phải được giữ bí mật để kết quả đánh giá được khách quan. Nếu ta khám phá dữ liệu nhiều quá, hiểu dữ liệu nhiều quá rồi mới tách các tập thì kết quả trên tập validation và tập kiểm tra có thể sẽ không được khách quan vì ta có thể dùng các hiểu biết khi khám phá dữ liệu (có tập validation và tập kiểm tra trong đó) để đưa ra các lựa chọn khi tiền xử lý và mô hình hóa dữ liệu (ở đây, mình muốn nói đến các hiểu biết mà chỉ đúng với tập dữ liệu cụ thể này chứ không thật sự là đúng)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Đưa ra câu hỏi cần trả lời"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quan trọng nhất ở bước này là ta phải xác định đâu là cột ouput. Về các cột input, nếu được thì ta cố gắng xác định những cột nào sẽ không dùng đến dựa vào ý nghĩa của các cột và sẽ bỏ luôn các cột này để đơn giản hóa cho các bước lúc sau (nhất là trong trường hợp dữ liệu có nhiều cột); với những cột mà không chắc chắn là nên bỏ hay nên giữ thì tạm cứ để đó, và ta sẽ làm ở bước tiền xử lý lúc sau.\n",
    "\n",
    "Trong cuộc thi trên Kaggle với bộ dữ liệu này, cột output đã được chỉ định sẵn là cột \"survival\" (sống/chết). Như vậy câu hỏi cần trả lời là: \n",
    "\n",
    "*Output - sống/chết -* được tính từ *input - các thông tin của hành khách -* theo công thức nào?\n",
    "\n",
    "Tạm thời ta sẽ để input là toàn bộ thông tin của hành khách, ta sẽ xác định cụ thể hơn ở bước tiền xử lý lúc sau.\n",
    "\n",
    "Việc tìm ra câu trả lời này cho câu hỏi này thật ra không có nhiều ý nghĩa trong thực tế; mục đích chính của cuộc thi này và của bài tập này là để tập luyện tiền xử lý + mô hình hóa dữ liệu. Trong đồ án cuối kỳ thì bạn cần giải thích để người đọc thấy được ý nghĩa thực tế của việc đi tìm câu trả lời cho câu hỏi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Khám phá dữ liệu (để biết cách tách các tập)\n",
    "Để biết cách tách các tập thì ta cần khám phá thêm cột output một ít:\n",
    "- Cột này hiện có kiểu dữ liệu là gì? Trong bài toán hồi qui thì cột output bắt buộc phải có dạng số; nếu hiện chưa có dạng số (ví dụ, số nhưng được lưu dưới dạng chuỗi) thì ta cần chuyển sang dạng số rồi mới tách các tập.\n",
    "- Cột này có giá trị thiếu không? Nếu có giá trị thiếu thì ta sẽ bỏ các dòng mà output có giá trị thiếu rồi mới tách các tập (loại học mà học từ dữ liệu trong đó output có giá trị thiếu được gọi là semi-supervised learning; trong phạm vi môn học, ta không đụng tới loại học này).\n",
    "- Nếu cột này có dạng categorical (phân lớp) thì tỉ lệ các lớp như thế nào? Nếu tỉ lệ các lớp bị chênh lệch nhau quá nhiều thì có thể ta sẽ cần qua lại bước thu thập dữ liệu và thu thập thêm để cho tỉ lệ các lớp không bị chênh lệnh quá nhiều (hoặc khi đánh giá ta cần có một độ lỗi phù hợp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cột output hiện có kiểu dữ liệu gì?\n",
    "data_df['Survived'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cột output có giá trị thiếu không?\n",
    "data_df['Survived'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tỉ lệ các lớp trong cột output?\n",
    "data_df['Survived'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, như vậy là không có vấn đề gì cả."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiền xử lý (tách các tập)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ ta sẽ thực hiện bước tiền xử lý là tách tập validation và tập kiểm tra ra (trong bài tập này thì chỉ tách tập validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Tách X và y\n",
    "y_sr = data_df[\"Survived\"] # sr là viết tắt của series\n",
    "X_df = data_df.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Tách tập huấn luyện và tập validation theo tỉ lệ 70%:30%\n",
    "train_X_df, val_X_df, train_y_sr, val_y_sr = train_test_split(X_df, y_sr, test_size=0.3, \n",
    "                                                              stratify=y_sr, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_sr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y_sr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_X_df.head().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "&#9889; Mình đã cố định `random_state` trong `train_test_split` để đảm bảo kết quả của mình ra giống với của bạn. Tuy nhiên, mình không biết là với các hệ điều hành khác nhau thì điều này có được đảm bảo không. Kết quả của câu lệnh `train_X_df.head().index` của mình ra 5 giá trị là: 232, 837, 640, 390, 598. Nếu của bạn ra khác thì bạn báo lại trên moodle, vì nếu ra khác thì các kết quả lúc sau của bạn cũng sẽ khác với của mình. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Khám phá dữ liệu (tập huấn luyện)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi đã tách ra các tập thì ta có thể thoải mái khám phá trên tập huấn luyện mà không lo sẽ làm kết quả trên tập validation và tập kiểm tra bị mất đi sự khách quan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mỗi cột input hiện đang có kiểu dữ liệu gì? Có cột nào có kiểu dữ liệu chưa phù hợp để có thể xử lý tiếp không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có vẻ các cột đều có kiểu dữ liệu phù hợp. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Với mỗi cột input có kiểu dữ liệu dạng số, các giá trị được phân bố như thế nào?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong `train_X_df`, có 5/10 cột có dtype không phải là object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.dtypes[train_X_df.dtypes != object]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhưng thật ra chỉ có 4 cột thật sự là dạng số: \"Age\", \"SibSp\", \"Parch\", \"Fare\". Còn cột \"Pclass\" thật ra là dạng categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "df = train_X_df[num_cols]\n",
    "def missing_ratio(df):\n",
    "    return (df.isna().mean() * 100).round(1)\n",
    "def lower_quartile(df):\n",
    "    return df.quantile(0.25).round(1)\n",
    "def median(df):\n",
    "    return df.quantile(0.5).round(1)\n",
    "def upper_quartile(df):\n",
    "    return df.quantile(0.75).round(1)\n",
    "df.agg([missing_ratio, 'min', lower_quartile, median, upper_quartile, 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Với mỗi cột input có kiểu dữ liệu không phải dạng số, các giá trị được phân bố như thế nào?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200) # Để nhìn rõ hơn\n",
    "cat_cols = list(set(train_X_df.columns) - set(num_cols))\n",
    "df = train_X_df[cat_cols]\n",
    "def missing_ratio(df):\n",
    "    return (df.isna().mean() * 100).round(1)\n",
    "def num_values(df):\n",
    "    return df.nunique()\n",
    "def value_ratios(c):\n",
    "    return dict((c.value_counts(normalize=True) * 100).round(1))\n",
    "df.agg([missing_ratio, num_values, value_ratios])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiền xử lý (tập huấn luyện) (3.5đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Đầu tiên, ta sẽ thêm và bỏ một số cột như sau: \n",
    "- Với cột \"Name\", ta sẽ tiến hành rút trích ra cột \"Title\" tương ứng, gồm các giá trị như \"Miss\", \"Mrs\", \"Mr\", \"Master\" ..., vì trong tên thì phần này có vẻ là sẽ có ích cho việc dự đoán sống/chết. Tuy nhiên, bạn sẽ thấy \"Title\" có khá nhiều giá trị khác nhau trong tập huấn luyện (bạn thử thì sẽ thấy có 14 giá trị), trong đó có các giá trị chỉ xuất hiện một hoặc một ít lần; nếu ta để nguyên thì khi chuyển sang dạng số bằng phương pháp one-hot sẽ có nhiều cột &#8594; dễ bị overfit. Ta sẽ xử lý vấn đề này như sau: chỉ lấy `num_top_titles` (ví dụ, 4) giá trị xuất hiện nhiều nhất, các giá trị còn lại sẽ được thay thế bằng giá trị \"Others\". Lúc sau, ta sẽ thí nghiệm để chọn ra giá trị `num_top_titles` phù hợp. Sau khi xử lý cột \"Title\" như vừa nói, ta thêm cột này vào dataframe và bỏ cột \"Name\" đi.\n",
    "- Bỏ cột \"Cabin\" vì cột này có quá nhiều giá thiếu.\n",
    "- Bỏ cột \"Ticket\" vì cột này có rất nhiều giá trị khác nhau, nếu chuyển sang dạng số bằng phương pháp one-hot thì sẽ làm tăng số lượng cột lên rất nhiều.\n",
    "\n",
    "Class `ColAdderDropper` ở dưới đây sẽ thực hiện các bước ở trên. Vì trong các bước ở trên, có bước ta cần tính toán các giá trị từ tập huấn luyện (`num_top_titles` giá trị của cột \"Title\" mà xuất hiện nhiều nhất) và dùng các giá trị này để \"transform\" tập dữ liệu (có thể là tập huấn luyện, có thể là tập validation hoặc tập kiểm tra) nên ta phải tự định nghĩa một class theo dạng \"transformer\" của Sklearn (để lúc sau có thể dùng pipeline của Sklearn) và trong đó ta phải tự định nghĩa phương thức `fit` và `transform` (còn nếu chỉ cần \"transform\" tập dữ liệu mà không cần tính toán giá trị gì từ tập huấn luyện thì dùng `FunctionTransformer` như trong file \"08-Demo.ipynb\" sẽ tiện lợi hơn). Bạn lưu ý: phương thức `fit` chỉ được dùng trên tập huấn luyện, còn phương thức `transform` (sau khi đã `fit`) có thể được dùng cho bất kỳ tập nào. Ở dưới, mình đã viết cho bạn phương thức `fit`; sau khi `fit`, các giá trị của cột \"Title\" cùng với số lần xuất hiện sẽ được lưu vào thuộc tính `self.title_counts_` (khi \"transform\" thì không cần dùng đến thông tin này, nhưng có thể bạn sẽ muốn xem thông in này), và `num_top_titles` giá trị xuất hiện nhiều nhất sẽ được lưu vào `self.top_titles_` (`num_top_titles` là siêu tham số mà phải chỉ định khi tạo ra một đối tượng thuộc class này). Nhiệm vụ của bạn là hoàn thành phương thức `transform` (trong đó, sẽ cần dùng đến `self.top_titles_`); bạn lưu ý không làm thay đổi dữ liệu ở `X_df` truyền vào.\n",
    "\n",
    "Ngoài ra, như bạn có thể thấy ở bên dưới, class `ColAdderDropper` được kế thừa từ 2 class của Sklearn là `BaseEstimator` và `TransformerMixin`. Việc kế thừa này giúp class của ta tự động có các phương thức như `set_params`, `get_params`, `fit_transform` (nếu không thì ta sẽ phải tự định nghĩa các phương thức này). Nếu muốn tìm hiểu thêm về cách viết class theo dạng của Sklearn, bạn có thể đọc [ở đây](https://scikit-learn.org/stable/developers/develop.html?highlight=baseestimator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0dda65a5c2f1394f88a1e4ac11ac7d8d",
     "grade": false,
     "grade_id": "cell-c2cb62acb65582f6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ColAdderDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_top_titles=1):\n",
    "        self.num_top_titles = num_top_titles\n",
    "    def fit(self, X_df, y=None):\n",
    "        title_col = X_df.Name.str.extract(r'([a-zA-z]+)\\.', expand=False)\n",
    "        self.title_counts_ = title_col.value_counts()\n",
    "        titles = list(self.title_counts_.index)\n",
    "        self.top_titles_ = titles[:max(1, min(self.num_top_titles, len(titles)))]\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST FIT METHOD\n",
    "col_adderdropper = ColAdderDropper(num_top_titles=4)\n",
    "col_adderdropper.fit(train_X_df)\n",
    "print(col_adderdropper.title_counts_)\n",
    "print()\n",
    "print(col_adderdropper.top_titles_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8894ed9a78d71de03e47528b355002af",
     "grade": true,
     "grade_id": "cell-7a54f3df0d0a2556",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST TRANSFORM METHOD\n",
    "fewer_cols_train_X_df = col_adderdropper.transform(train_X_df)\n",
    "assert set(fewer_cols_train_X_df.columns) == {'Age', 'Embarked', 'Fare', 'Parch', 'Pclass', 'Sex', 'SibSp', 'Title'}\n",
    "assert np.all(fewer_cols_train_X_df['Title'].value_counts() == \\\n",
    "              pd.Series([357, 125, 89, 32, 20], ['Mr', 'Miss', 'Mrs', 'Master', 'Others']))\n",
    "fewer_cols_train_X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Đến đây, các cột dạng số (numerical) gồm: \"Age\", \"SibSp\", \"Parch\", \"Fare\"; các cột không phải dạng số (categorical) và không có thứ tự gồm: \"Sex\", \"Embarked\", \"Title\"; cột không phải dạng số và có thứ tự: \"PClass\". Các bước tiền xử lý tiếp theo như sau:\n",
    "- Với các cột dạng số, ta sẽ điền giá trị thiếu bằng giá trị mean của cột <font color=gray>(gợi ý: dùng `SimpleImputer` trong Sklearn)</font>. Với *tất cả* các cột dạng số trong tập huấn luyện, ta đều cần tính mean, vì ta không biết được cột nào sẽ bị thiếu giá trị khi dự đoán với các véc-tơ input mới. \n",
    "- Với các cột không phải dạng số và không có thứ tự:\n",
    "    - Ta sẽ điền giá trị thiếu bằng giá trị mode (giá trị xuất hiện nhiều nhất) của cột <font color=gray>(gợi ý: dùng `SimpleImputer` trong Sklearn)</font>. Với *tất cả* các cột không có dạng số và không có thứ tự, ta đều cần tính mode, vì ta không biết được cột nào sẽ bị thiếu giá trị khi dự đoán với các véc-tơ input mới.\n",
    "    - Sau đó, ta sẽ chuyển sang dạng số bằng phương pháp mã hóa one-hot <font color=gray>(gợi ý: dùng `OneHotEncoder` trong Sklearn, để ý tham số `handle_unknown` vì khi dự đoán với các véc-tơ input mới ...)</font>.\n",
    "- Với cột không phải dạng số và có thứ tự (cột \"PClass\"):\n",
    "    - Ta sẽ điền giá trị thiếu bằng giá trị mode (giá trị xuất hiện nhiều nhất) của cột.\n",
    "    - Cột này đã được chuyển sang dạng số rồi nên ta không cần chuyển nữa.\n",
    "- Cuối cùng, khi tất cả các cột đã được điền giá trị thiếu và đã có dạng số, ta sẽ tiến hành chuẩn hóa bằng cách trừ đi mean và chia cho độ lệch chuẩn của cột để giúp cho các thuật toán cực tiểu hóa như Gradient Descent, LBFGS, ... hội tụ nhanh hơn <font color=gray>(gợi ý: dùng `StandardScaler` trong Sklearn)</font>.\n",
    "\n",
    "Nhiệm vụ của bạn là tạo ra một pipeline, đặt tên là `preprocess_pipeline`, bao gồm: bước thêm cột `Title` và bỏ các cột (đã cài ở class `ColAdderDropper`, bạn để `num_top_titles=4`), và tất cả các bước ở đây. Sau khi tạo ra được pipeline này rồi, bạn sẽ gọi phương thức `fit_transform` với đầu vào là `train_X_df` để tính các giá trị từ tập huấn luyện (ví dụ, `top_titles_` ở bước thêm và xóa cột, mean và mode ở bước xử lý giá trị thiếu, mean và độ lệch chuẩn ở bước chuẩn hóa) và đồng thời tiền xử lý `train_X_df`; kết quả trả về sẽ là `train_X_df` sau khi đã tiền xử lý, là một mảng Numpy, bạn đặt tên là `preprocessed_train_X`. <font color=gray>(Gợi ý: bạn đọc cách sử dụng pipeline ở [document](https://scikit-learn.org/stable/modules/compose.html#transforming-target-in-regression), có thể bỏ qua mục 6.1.2; bạn sẽ cần dùng `Pipeline`/`make_pipeline` và `ColumnTransformer`/`make_column_transformer`.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7a1d4ae5e4fa50b60b4998de6be96a1",
     "grade": false,
     "grade_id": "cell-ae75d7dfa7256c7f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "nume_cols = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "unorder_cate_cols = ['Sex', 'Embarked', 'Title']\n",
    "order_cate_cols = ['Pclass']\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e1467ce6e547f6d16ca0fe78775b3ad",
     "grade": true,
     "grade_id": "cell-1cf65ae2cdb14c0c",
     "locked": true,
     "points": 2.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert preprocessed_train_X.shape == (623, 15)\n",
    "row0 = {-0.041, -0.481, -0.48 , -0.479, -0.736,  0.736, -0.478, -0.295,\n",
    "        0.603, -0.233, -0.501,  0.863, -0.408, -0.182,  0.844}\n",
    "row1 = {-0.664, -0.481, -0.48 , -0.463, -0.736,  0.736, -0.478, -0.295,\n",
    "        0.603, -0.233, -0.501,  0.863, -0.408, -0.182,  0.844}\n",
    "assert set(preprocessed_train_X[0].round(3)) == row0\n",
    "assert set(preprocessed_train_X[1].round(3)) == row1\n",
    "preprocess_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Tiền xử lý (tập validation) (1.5đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Một khi đã có `preprocess_pipeline` với các giá trị (`top_titles_`, mean, mode, ...) đã được tính từ tập huấn luyện, ta có thể dễ dàng dùng phương thức `transform` để tiền xử lý cho các véc-tơ input mới trong tập validation và tập kiểm tra. Dưới đây, bạn sẽ làm như vậy để tiền xử lý cho `val_X_df` và lưu kết quả vào `preprocessed_val_X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "986f547abfe534258eb2c41f692c1084",
     "grade": false,
     "grade_id": "cell-5b00ff693785976e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a78ff2194ae58fc4d73215de771a775b",
     "grade": true,
     "grade_id": "cell-b9c978682fecdf3c",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "assert preprocessed_val_X.shape == (268, 15)\n",
    "row0 = {-0.664, -0.481, -0.48 , -0.48 , -0.736,  0.736, -0.478,  3.385,\n",
    "       -1.659, -0.233, -0.501,  0.863, -0.408, -0.182,  0.844}\n",
    "row1 = {-1.988,  1.38 ,  0.831,  0.098,  1.358, -1.358, -0.478, -0.295,\n",
    "        0.603, -0.233,  1.996, -1.158, -0.408, -0.182, -0.346}\n",
    "assert set(preprocessed_val_X[0].round(3)) == row0\n",
    "assert set(preprocessed_val_X[1].round(3)) == row1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Giải thích tại sao không nên làm 2 cách sau:\n",
    "- Tiền xử lý tập validation bằng các giá trị  (top_titles_, mean, mode, ...) được tính từ tập validation\n",
    "- Hoặc tiền xử lý tất cả dữ liệu rồi mới tách tập validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a1567a9361126ee5dd2d6371498efda",
     "grade": true,
     "grade_id": "cell-c9f9e4ac63684628",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Tiền xử lý + mô hình hóa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tìm mô hình tốt nhất (4đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Ta sẽ sử dụng mô hình Neural Net để phân lớp. Bạn sẽ tạo ra một pipeline từ đầu đến cuối bao gồm: các bước tiền xử lý ở trên + Neural Net (với các siêu tham số `hidden_layer_sizes=(20), activation='tanh', solver='lbfgs', random_state=0, max_iter=2500`). Bạn đặt tên cho pipeline này là `full_pipeline`. Việc tạo ra một pipeline từ đầu đến cuối như này có các lợi ích sau:\n",
    "- Giúp đơn giản hóa: \n",
    "    - Để huấn luyện từ đầu tới cuối, chỉ cần gọi phương thức `fit` của pipeline này trên tập huấn luyện dạng thô. Lúc này, các \"transformer\" ở các bước tiền xử lý sẽ gọi `fit_transform`, còn \"classifier\" ở cuối sẽ gọi `fit`.\n",
    "    - Với các véc-tơ input ở dạng thô, để dự đoán thì chỉ cần gọi phương thức `predict` của pipeline. Lúc này, các \"transformer\" ở các bước tiền xử lý sẽ gọi `transform`, còn \"classifier\" ở cuối sẽ gọi `predict`.\n",
    "- Giúp tránh tiền xử lý tập validation/kiểm-tra sai cách (như đã nói ở mục \"Tiền xử lý (tập validation)\" ở trên). Để làm sai cũng khó à nha ;-).\n",
    "- Giúp dễ dàng thử nghiệm đồng thời các giá trị của các siêu tham số ở các bước trong pipeline (sẽ làm ở ngay dưới).\n",
    "\n",
    "Sau khi đã có được pipeline từ đầu đến cuối này, bạn sẽ thử nghiệm:\n",
    "- Siêu tham số `alpha` (mức độ L2 regularization hay weight decay) của `MLPClassifier` với 5 giá trị khác nhau: 0.1, 1, 10, 100, 1000.\n",
    "- Siêu tham số `num_top_titles` của `ColAdderDropper` (ở bước tiền xử lý) với 6 giá trị khác nhau: 1, 3, 5, 7, 9, 11.\n",
    "\n",
    "Để gán lại giá trị `alpha` và `num_top_titles` cho `full_pipeline`, bạn sẽ dùng phương thức `set_params`: \n",
    "\n",
    "`full_pipeline.set_params(coladderdropper__num_top_titles=..., mlpclassifier__alpha=...)`\n",
    "\n",
    "Trong câu lệnh ở trên, `coladderdropper` và `mlpclassifier` là tên của 2 bước trong `full_pipeline` (2 bước nào thì chắc bạn cũng đoán được). Nếu bạn tạo pipeline bằng `make_pipeline` thì tên của các bước sẽ được tự động lấy là tên của các class và được viết thường như 2 tên ở trên. Còn nếu bạn dùng `Pipeline` và tự đặt tên cho các bước thì bạn dùng tên của bạn trong phương thức `set_params`.  \n",
    "\n",
    "Như vậy, tổng cộng bạn sẽ thử nghiệm $5\\times6 = 30$ mô hình khác nhau, với mỗi mô hình bạn sẽ: huấn luyện trên tập huấn luyện, tính độ lỗi trên tập huấn luyện và tập validation rồi `append` độ lỗi vào 2 list tương ứng là `train_errs` và `var_errs` (để dễ nhìn, bạn tính độ lỗi theo đơn vị %, nghĩa là có giá trị từ 0-100 chứ không phải từ 0-1). Bạn lưu lại độ lỗi nhỏ nhất trên tập validation và giá trị `alpha` và `num_top_titles` tương ứng lần lượt vào biến `best_val_err`, `best_alpha`, `best_num_top_titles`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb0c3953788eff39e4c9c0cd5c2dcde6",
     "grade": false,
     "grade_id": "cell-fdd12a79fb590313",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tạo full pipeline\n",
    "nume_cols = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "unorder_cate_cols = ['Sex', 'Embarked', 'Title']\n",
    "order_cate_cols = ['Pclass']\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Thử nghiệm với các giá trị khác nhau của các siêu tham số\n",
    "# và chọn ra các giá trị tốt nhất\n",
    "train_errs = []\n",
    "val_errs = []\n",
    "alphas = [0.1, 1, 10, 100, 1000]\n",
    "num_top_titles_s = [1, 3, 5, 7, 9, 11]\n",
    "best_val_err = float('inf'); best_alpha = None; best_num_top_titles = None\n",
    "for alpha in alphas:\n",
    "    for num_top_titles in num_top_titles_s:\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "'Finish!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f33688c1c8f4b1a71567209f5872b5e7",
     "grade": true,
     "grade_id": "cell-0b98eab69b5f1ff7",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert round(best_val_err, 3) == 16.045\n",
    "assert best_alpha == 10\n",
    "assert best_num_top_titles == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trực quan hóa kết quả\n",
    "train_errs_df = pd.DataFrame(data=np.array(train_errs).reshape(len(alphas), -1),\n",
    "                             index=alphas, columns=num_top_titles_s)\n",
    "val_errs_df = pd.DataFrame(data=np.array(val_errs).reshape(len(alphas), -1), \n",
    "                           index=alphas, columns=num_top_titles_s)\n",
    "min_err = min(min(train_errs), min(val_errs))\n",
    "max_err = max(max(train_errs), max(val_errs))\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(train_errs_df, vmin=min_err, vmax=max_err, square=True, annot=True, \n",
    "            cbar=False, fmt='.1f', cmap='Reds')\n",
    "plt.title('train errors'); plt.xlabel('num_top_titles'); plt.ylabel('alpha')\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(val_errs_df, vmin=min_err, vmax=max_err, square=True, annot=True, \n",
    "            cbar=False, fmt='.1f', cmap='Reds')\n",
    "plt.title('validation errors'); plt.xlabel('num_top_titles'); plt.ylabel('alpha');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Nhận xét về ảnh hưởng của siêu tham số `alpha` (có sao thì bạn nói vậy, chỗ nào không biết thì nói là không biết): \n",
    "- Bạn kỳ vọng khi `alpha` thay đổi thì độ lỗi trên tập huấn luyện và tập validation sẽ thay đổi như thế nào? Tại sao bạn lại kỳ vọng như vậy?\n",
    "- Kết quả ở trên có giống như kỳ vọng của bạn không? Nếu không thì bạn nghĩ xem tại sao lại như vậy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e0471605e1a0872e36754fa0f485aa1",
     "grade": true,
     "grade_id": "cell-4debcfe69b8e605b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Nhận xét về ảnh hưởng của siêu tham số `num_top_titles` (có sao thì bạn nói vậy, chỗ nào không biết thì nói là không biết): \n",
    "- Bạn kỳ vọng khi `num_top_titles` thay đổi thì độ lỗi trên tập huấn luyện và tập validation sẽ thay đổi như thế nào? Tại sao bạn lại kỳ vọng như vậy?\n",
    "- Kết quả ở trên có giống như kỳ vọng của bạn không? Nếu không thì bạn nghĩ xem tại sao lại như vậy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49982bae0349935c9ca94046bf830735",
     "grade": true,
     "grade_id": "cell-94737f293bd3c2a8",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuối cùng, bạn sẽ huấn luyện lại `full_pipeline` trên `X_df` và `y_sr` (tập huấn luyện + tập validation) với `best_alpha` và `best_num_top_titles` tìm được ở trên để ra được mô hình cụ thể cuối cùng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e771c0641435719860146ab39be71ef8",
     "grade": true,
     "grade_id": "cell-34157b0f98b9d3f5",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Đánh giá mô hình tìm được (1đ)\n",
    "Bạn sẽ dùng mô hình cụ thể cuối cùng ở trên để dự đoán với các input trong tập test (file \"test.csv\") và submit kết quả dự đoán lên Kaggle. Để có thể submit thì bạn phải tạo ra file csv có 2 cột: cột thứ nhất là id của các hành khách trong tập test, cột thứ hai là giá trị dự đoán của bạn (1 - sống, và 0 - chết). Bạn có thể xem file mẫu `submission.csv` mà mình đính kèm. Bạn đặt tên file của bạn là `my_preds.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "226b0f0ebb7e79c2866d02164cec9e2d",
     "grade": false,
     "grade_id": "cell-e184d7a3003ba334",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4af5baeded7464b6854a1a123c5465c2",
     "grade": true,
     "grade_id": "cell-dbdc218117501513",
     "locked": true,
     "points": 0.75,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "my_preds_df = pd.read_csv('my_preds.csv', index_col=0)\n",
    "assert round(my_preds_df['Survived'].mean(), 3) == 0.366\n",
    "assert np.all(my_preds_df.iloc[:5].values.reshape(-1) == np.array([0, 0, 0, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Kế đến, bạn sẽ submit file csv chứa kết quả dự đoán lên [Kaggle](https://www.kaggle.com/c/titanic) (bạn sẽ cần tạo một account trên Kaggle), và ghi nhận lại độ lỗi trên tập test ở cell phía dưới (score trên Kaggle là độ chính xác)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b369b7d7c79e9110cb16f28db1c29ef0",
     "grade": true,
     "grade_id": "cell-0a8a2d0f116f035d",
     "locked": false,
     "points": 0.25,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.009px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
