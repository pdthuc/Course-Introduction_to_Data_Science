{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# BT03: Tiền xử lý và chống overfitting\n",
    "\n",
    "Họ tên: Huỳnh Minh Huấn\n",
    "\n",
    "MSSV: 1612858"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Cách làm bài và nộp bài\n",
    "&#9889; Bạn lưu ý là mình sẽ dùng chương trình hỗ trợ chấm bài nên bạn cần phải tuân thủ chính xác qui định mà mình đặt ra, nếu không rõ thì hỏi, chứ không nên tự tiện làm theo ý của cá nhân.\n",
    "\n",
    "**Cách làm bài**\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này. Đầu tiên, bạn điền họ tên và MSSV vào phần đầu file ở bên trên. Trong file, bạn làm bài ở những chỗ có ghi là:\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "hoặc đối với những phần code không bắt buộc thì là:\n",
    "```python\n",
    "# YOUR CODE HERE (OPTION)\n",
    "```\n",
    "hoặc đối với markdown cell thì là:\n",
    "```markdown\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "Tất nhiên, khi làm thì bạn xóa dòng `raise NotImplementedError()` đi.\n",
    "Đối những phần yêu cầu code thì thường ở ngay phía dưới sẽ có một (hoặc một số) cell chứa các bộ test để giúp bạn biết đã code đúng hay chưa; nếu chạy cell này không có lỗi gì thì có nghĩa là qua được các bộ test. Trong một số trường hợp, các bộ test có thể sẽ không đầy đủ; nghĩa là, nếu không qua được test thì là code sai, nhưng nếu qua được test thì chưa chắc đã đúng.\n",
    "\n",
    "Trong khi làm bài, bạn có thể cho in ra màn hình, tạo thêm các cell để test. Nhưng khi nộp bài thì bạn xóa các cell mà bạn tự tạo, xóa hoặc comment các câu lệnh in ra màn hình. Bạn lưu ý <font color=red>không được tự tiện xóa các cell hay sửa code của Thầy</font> (trừ những chỗ được phép sửa như đã nói ở trên).\n",
    "\n",
    "Trong khi làm bài, thường xuyên `Ctrl + S` để lưu lại bài làm của bạn, tránh mất mát thông tin.\n",
    "\n",
    "\n",
    "*Nên nhớ mục tiêu chính ở đây là <font color=green>học, học một cách chân thật</font>. Bạn có thể thảo luận ý tưởng với bạn khác, nhưng <font color=green>code và bài làm phải là của bạn, dựa trên sự hiểu thật sự của bạn</font>. <font color=red>Nếu vi phạm thì sẽ bị 0 điểm cho toàn bộ môn học.</font>*\n",
    "\n",
    "**Cách nộp bài**\n",
    "\n",
    "Khi chấm bài, đầu tiên mình sẽ chọn `Kernel` - `Restart Kernel & Run All Cells`, để restart và chạy tất cả các cell trong notebook của bạn; do đó, trước khi nộp bài, bạn nên chạy thử `Kernel` - `Restart Kernel & Run All Cells` để đảm bảo mọi chuyện diễn ra đúng như mong đợi.\n",
    "\n",
    "Sau đó, bạn tạo thư mục nộp bài theo cấu trúc sau:\n",
    "- Thư mục `MSSV` (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`)\n",
    "    - Thư mục `BT03`\n",
    "        - File `BT03-TienXuLy_ChongOverfit.ipynb` (không cần nộp các file khác)\n",
    "\n",
    "Cuối cùng, bạn nén thư mục `MSSV` này lại và nộp ở link trên moodle. <font color=red>Bạn lưu ý tuân thủ chính xác cấu trúc này.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Mô tả dữ liệu\n",
    "Bộ dữ liệu được sử dụng là bộ [Kaggle Titanic](https://www.kaggle.com/c/titanic); trong đó, input là thông tin của hành khách trên tàu Titanic, output là một trong hai lớp sống/chết (1/0). Mình có đính kèm các file dữ liệu mà Kaggle cung cấp: `train.csv` - tập huấn luyện, `test.csv` - tập kiểm tra (chỉ có input). Bạn xem ý nghĩa của các cột trong file `description.txt` đính kèm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # seaborn là thư viện được xây trên matplotlib, giúp việc visualization đỡ khổ hơn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# You can also import other things ...\n",
    "# YOUR CODE HERE (OPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Đọc tập huấn luyện vào data frame và tách ra tập validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('train.csv', index_col=0)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Tách X và y\n",
    "y_sr = data_df[\"Survived\"] # sr là viết tắt của series\n",
    "X_df = data_df.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Tách tập train và tập validation theo tỉ lệ 70%:30%\n",
    "train_X_df, val_X_df, train_y_sr, val_y_sr = train_test_split(X_df, y_sr, test_size=0.3, \n",
    "                                                              stratify=y_sr, random_state=0)\n",
    "\n",
    "train_X_df.head().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "&#9889; Mình đã cố định `random_state` trong `train_test_split` để đảm bảo kết quả của mình ra giống với của bạn. Tuy nhiên, mình không biết là với các hệ điều hành khác nhau thì điều này có được đảm bảo không. Kết quả của câu lệnh `train_X_df.head().index` của mình ra 5 giá trị là: `[232, 837, 640, 390, 598]`. Nếu của bạn ra khác thì bạn báo lại trên moodle, vì nếu ra khác thì các kết quả lúc sau của bạn cũng sẽ khác với của mình. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_X_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "val_X_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Tiền xử lý tập huấn luyện (3.5đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Đầu tiên, ta sẽ thêm và bỏ một số cột như sau: \n",
    "- Với cột `Name`, ta sẽ tiến hành rút trích ra cột `Title` tương ứng, gồm các giá trị như `Miss`, `Mrs`, `Mr`, `Master` ..., vì trong tên thì phần này có vẻ là sẽ có ích cho việc dự đoán sống/chết. Tuy nhiên, bạn sẽ thấy `Title` có khá nhiều giá trị khác nhau trong tập huấn luyện (bạn thử thì sẽ thấy có 14 giá trị), trong đó có các giá trị chỉ xuất hiện một hoặc một ít lần; nếu ta để nguyên thì khi chuyển sang dạng số bằng phương pháp one-hot sẽ có nhiều cột &#8594; dễ bị overfit. Ta sẽ xử lý vấn đề này như sau: chỉ lấy `num_top_titles` (ví dụ, 4) giá trị xuất hiện nhiều nhất, các giá trị còn lại sẽ được thay thế bằng giá trị `Others`. Lúc sau, ta sẽ thí nghiệm để chọn ra giá trị `num_top_titles` phù hợp. Sau khi xử lý cột `Title` như vừa nói, ta thêm cột này vào dataframe và bỏ cột `Name` đi.\n",
    "- Bỏ cột `Cabin` vì cột này có quá nhiều giá thiếu.\n",
    "- Bỏ cột `Ticket` vì cột này có rất nhiều giá trị khác nhau, nếu chuyển sang dạng số bằng phương pháp one-hot thì sẽ làm tăng số lượng cột lên rất nhiều.\n",
    "\n",
    "Class `ColAdderDropper` ở dưới đây sẽ thực hiện các bước ở trên. Vì trong các bước ở trên, có bước ta cần tính toán các giá trị từ tập huấn luyện (`num_top_titles` giá trị của cột `Title` mà xuất hiện nhiều nhất) và dùng các giá trị này để \"transform\" tập dữ liệu (có thể là tập huấn luyện, có thể là tập validation hoặc tập kiểm tra) nên ta phải tự định nghĩa một class theo dạng \"transformer\" của Sklearn (để lúc sau có thể dùng pipeline của Sklearn) và trong đó ta phải tự định nghĩa phương thức `fit` và `transform` (còn nếu chỉ cần \"transform\" tập dữ liệu mà không cần tính toán giá trị gì từ tập huấn luyện thì dùng `FunctionTransformer` như trong file \"10-Demo.ipynb\" sẽ tiện lợi hơn). Bạn lưu ý: phương thức `fit` chỉ được dùng trên tập huấn luyện, còn phương thức `transform` (sau khi đã `fit`) có thể được dùng cho bất kỳ tập nào. Ở dưới, mình đã viết cho bạn phương thức `fit`; sau khi `fit`, các giá trị của cột `Title` cùng với số lần xuất hiện sẽ được lưu vào thuộc tính `self.title_counts_` (khi \"transform\" thì không cần dùng đến thông tin này, nhưng có thể bạn sẽ muốn xem thông in này), và `num_top_titles` giá trị xuất hiện nhiều nhất sẽ được lưu vào `self.top_titles_` (`num_top_titles` là siêu tham số mà phải chỉ định khi tạo ra một đối tượng thuộc class này). Nhiệm vụ của bạn là hoàn thành phương thức `transform` (trong đó, sẽ cần dùng đến `self.top_titles_`); bạn lưu ý không làm thay đổi dữ liệu ở `X_df` truyền vào.\n",
    "\n",
    "Ngoài ra, như bạn có thể thấy ở bên dưới, class `ColAdderDropper` được kế thừa từ 2 class của Sklearn là `BaseEstimator` và `TransformerMixin`. Việc kế thừa này giúp class của ta tự động có các phương thức như `set_params`, `get_params`, `fit_transform` (nếu không thì ta sẽ phải tự định nghĩa các phương thức này). Nếu muốn tìm hiểu thêm về cách viết class theo dạng của Sklearn, bạn có thể đọc [ở đây](https://scikit-learn.org/stable/developers/develop.html?highlight=baseestimator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0dda65a5c2f1394f88a1e4ac11ac7d8d",
     "grade": false,
     "grade_id": "cell-c2cb62acb65582f6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ColAdderDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_top_titles=1):\n",
    "        self.num_top_titles = num_top_titles\n",
    "    def fit(self, X_df, y=None):\n",
    "        title_col = X_df.Name.str.extract(r'([a-zA-z]+)\\.', expand=False)\n",
    "        self.title_counts_ = title_col.value_counts()\n",
    "        titles = list(self.title_counts_.index)\n",
    "        self.top_titles_ = titles[:max(1, min(self.num_top_titles, len(titles)))]\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        # YOUR CODE HERE\n",
    "        df = X_df.copy()\n",
    "        title_col = df.Name.str.extract(\"([a-zA-z]+)\\.\", expand=False)\n",
    "        title_col[~title_col.isin(self.top_titles_)] = 'Others'\n",
    "        df[\"Title\"] = title_col\n",
    "        dropped_cols = ['Name', 'Ticket', 'Cabin']\n",
    "        df.drop(dropped_cols, axis=1, inplace=True)\n",
    "        return df\n",
    "        #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST FIT METHOD\n",
    "col_adderdropper = ColAdderDropper(num_top_titles=4)\n",
    "col_adderdropper.fit(train_X_df)\n",
    "print(col_adderdropper.title_counts_)\n",
    "print()\n",
    "print(col_adderdropper.top_titles_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8894ed9a78d71de03e47528b355002af",
     "grade": true,
     "grade_id": "cell-7a54f3df0d0a2556",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST TRANSFORM METHOD\n",
    "fewer_cols_train_X_df = col_adderdropper.transform(train_X_df)\n",
    "assert set(fewer_cols_train_X_df.columns) == {'Age', 'Embarked', 'Fare', 'Parch', 'Pclass', 'Sex', 'SibSp', 'Title'}\n",
    "assert np.all(fewer_cols_train_X_df['Title'].value_counts() == \\\n",
    "              pd.Series([357, 125, 89, 32, 20], ['Mr', 'Miss', 'Mrs', 'Master', 'Others']))\n",
    "fewer_cols_train_X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Đến đây, các cột dạng số (numerical) gồm:`Pclass`, `Age`, `SibSp`, `Parch`, `Fare`; các cột dạng chuỗi có giá trị rời rạc không thứ tự (categorical) gồm: `Sex`, `Embarked`, `Title`. Các bước tiền xử lý tiếp theo như sau:\n",
    "- Với các cột dạng số, ta sẽ điền giá trị thiếu bằng giá trị mean của cột <font color=blue>(gợi ý: dùng `SimpleImputer` trong Sklearn)</font>. Với *tất cả* các cột dạng số trong tập huấn luyện, ta đều cần tính mean, vì ta không biết được cột nào sẽ bị thiếu giá trị khi dự đoán với các véc-tơ input mới. \n",
    "- Với các cột dạng chuỗi có giá trị rời rạc không thứ tự:\n",
    "    - Ta sẽ điền giá trị thiếu bằng giá trị mode (giá trị xuất hiện nhiều nhất) của cột <font color=blue>(gợi ý: dùng `SimpleImputer` trong Sklearn)</font>. Với *tất cả* các cột dạng chuỗi có giá trị rời rạc không thứ tự trong tập huấn luyện, ta đều cần tính mode, vì ta không biết được cột nào sẽ bị thiếu giá trị khi dự đoán với các véc-tơ input mới.\n",
    "    - Sau đó, ta sẽ chuyển sang dạng số bằng phương pháp mã hóa one-hot <font color=blue>(gợi ý: dùng `OneHotEncoder` trong Sklearn, để ý tham số `handle_unknown` vì khi dự đoán với các véc-tơ input mới ...)</font>.\n",
    "- Cuối cùng, khi tất cả các cột đã được điền giá trị thiếu và đã có dạng số, ta sẽ tiến hành chuẩn hóa bằng cách trừ đi mean và chia cho độ lệch chuẩn của cột để giúp cho các thuật toán cực tiểu hóa như Gradient Descent, LBFGS, ... hội tụ nhanh hơn <font color=blue>(gợi ý: dùng `StandardScaler` trong Sklearn)</font>.\n",
    "\n",
    "Nhiệm vụ của bạn là tạo ra một pipeline, đặt tên là `preprocess_pipeline`, bao gồm: bước thêm cột `Title` và bỏ các cột (đã cài ở class `ColAdderDropper`, bạn để `num_top_titles=4`), và tất cả các bước ở đây. Sau khi tạo ra được pipeline này rồi, bạn sẽ gọi phương thức `fit_transform` với đầu vào là `train_X_df` để tính các giá trị từ tập huấn luyện (ví dụ, `top_titles_` ở bước thêm và xóa cột, mean và mode ở bước xử lý giá trị thiếu, mean và độ lệch chuẩn ở bước chuẩn hóa) và đồng thời tiền xử lý `train_X_df`; kết quả trả về sẽ là `train_X_df` sau khi đã tiền xử lý, là một mảng Numpy, bạn đặt tên là `preprocessed_train_X`. <font color=blue>(Gợi ý: bạn đọc cách sử dụng pipeline ở [document](https://scikit-learn.org/stable/modules/compose.html#transforming-target-in-regression), có thể bỏ qua mục 6.1.2; bạn sẽ cần dùng `Pipeline`/`make_pipeline` và `ColumnTransformer`/`make_column_transformer`.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7449dd24755f72f899f815b2d09f0df",
     "grade": false,
     "grade_id": "cell-ae75d7dfa7256c7f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "nume_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "cate_cols = ['Sex', 'Embarked', 'Title']\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "imp_mean = SimpleImputer(strategy='mean')\n",
    "imp_mode = SimpleImputer(strategy='most_frequent')\n",
    "encoding = OneHotEncoder()\n",
    "categorical_transformer = make_pipeline(imp_mode, encoding)\n",
    "\n",
    "colTransform = ColumnTransformer(transformers=[('numerical', imp_mean, nume_cols),\\\n",
    "                                               ('categorical', categorical_transformer, cate_cols)])\n",
    "colNormalize = StandardScaler()\n",
    "preprocess_pipeline = make_pipeline(col_adderdropper, colTransform, colNormalize)\n",
    "\n",
    "preprocessed_train_X = preprocess_pipeline.fit_transform(train_X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f190452c4d87759ef5fc8b49b1bc2bf",
     "grade": true,
     "grade_id": "cell-1cf65ae2cdb14c0c",
     "locked": true,
     "points": 2.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert preprocessed_train_X.shape == (623, 15)\n",
    "row0 = {-0.736, -0.501, -0.481, -0.48, -0.479, -0.478, -0.408, -0.295, -0.233, -0.182, -0.041, 0.603, 0.736, 0.844, 0.863}\n",
    "row1 = {-0.736, -0.664, -0.501, -0.481, -0.48, -0.478, -0.463, -0.408, -0.295, -0.233, -0.182, 0.603, 0.736, 0.844, 0.863}\n",
    "assert set(np.round(preprocessed_train_X[0], decimals=3)) == row0\n",
    "assert set(np.round(preprocessed_train_X[1], decimals=3)) == row1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Tiền xử lý tập validation (1.5đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Một khi đã có `preprocess_pipeline` với các giá trị (`top_titles_`, mean, mode, ...) đã được tính từ tập huấn luyện, ta có thể dễ dàng dùng phương thức `transform` để tiền xử lý cho các véc-tơ input mới trong tập validation và tập test. Dưới đây, bạn sẽ làm như vậy để tiền xử lý cho `val_X_df` và lưu kết quả vào `preprocessed_val_X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "986f547abfe534258eb2c41f692c1084",
     "grade": false,
     "grade_id": "cell-5b00ff693785976e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "preprocessed_val_X = full_preprocess_pipeline.transform(val_X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1cfaf89e2a1eb8b5b1080c889fa543e",
     "grade": true,
     "grade_id": "cell-b9c978682fecdf3c",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "assert preprocessed_val_X.shape == (268, 15)\n",
    "row0 = {-1.659, -0.736, -0.664, -0.501, -0.481, -0.48, -0.478, -0.408, -0.233, -0.182, 0.736, 0.844, 0.863, 3.385}\n",
    "row1 = {-1.988, -1.358, -1.158, -0.478, -0.408, -0.346, -0.295, -0.233, -0.182, 0.098, 0.603, 0.831, 1.358, 1.38, 1.996}\n",
    "assert set(np.round(preprocessed_val_X[0], 3)) == row0\n",
    "assert set(np.round(preprocessed_val_X[1], 3)) == row1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Giải thích tại sao không nên làm 2 cách sau:\n",
    "- Tiền xử lý tập validation bằng các giá trị  (top_titles_, mean, mode, ...) được tính từ tập validation\n",
    "- Hoặc tiền xử lý tất cả dữ liệu rồi mới tách tập validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a1567a9361126ee5dd2d6371498efda",
     "grade": true,
     "grade_id": "cell-c9f9e4ac63684628",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Tạo một pipeline từ đầu đến cuối và chọn lựa mô hình tốt nhất (4đ)\n",
    "Ta sẽ sử dụng mô hình Neural Net để phân lớp. Bạn sẽ tạo ra một pipeline từ đầu đến cuối bao gồm: các bước tiền xử lý ở trên + Neural Net (với các siêu tham số `hidden_layer_sizes=(20), activation='tanh', solver='lbfgs', random_state=0, max_iter=500`). Bạn đặt tên cho pipeline này là `full_pipeline`. Việc tạo ra một pipeline từ đầu đến cuối như này có các lợi ích sau:\n",
    "- Giúp đơn giản hóa: \n",
    "    - Để huấn luyện từ đầu tới cuối, chỉ cần gọi phương thức `fit` của pipeline này trên tập huấn luyện dạng thô. Lúc này, các \"transformer\" ở các bước tiền xử lý sẽ gọi `fit_transform`, còn \"classifier\" ở cuối sẽ gọi `fit`.\n",
    "    - Với các véc-tơ input ở dạng thô, để dự đoán thì chỉ cần gọi phương thức `predict` của pipeline. Lúc này, các \"transformer\" ở các bước tiền xử lý sẽ gọi `transform`, còn \"classifier\" ở cuối sẽ gọi `predict`.\n",
    "- Giúp tránh tiền xử lý tập validation/kiểm-tra sai cách (như đã nói ở mục \"Tiền xử lý tập validation\" ở trên). Đố bạn làm sai được đấy ;-).\n",
    "- Giúp dễ dàng thử nghiệm đồng thời các giá trị của các siêu tham số ở các bước trong pipeline (sẽ làm ở ngay dưới).\n",
    "\n",
    "Sau khi đã có được pipeline từ đầu đến cuối này, bạn sẽ thử nghiệm:\n",
    "- Siêu tham số `alpha` (mức độ L2 regularization) của `MLPClassifier` với 5 giá trị khác nhau: 0.1, 1, 10, 100, 1000.\n",
    "- Siêu tham số `num_top_titles` của `ColAdderDropper` (ở bước tiền xử lý) với 6 giá trị khác nhau: 1, 3, 5, 7, 9, 11.\n",
    "\n",
    "Để gán lại giá trị `alpha` và `num_top_titles` cho `full_pipeline`, bạn sẽ dùng phương thức `set_params`: \n",
    "\n",
    "`full_pipeline.set_params(coladderdropper__num_top_titles=..., mlpclassifier__alpha=...)`\n",
    "\n",
    "Trong câu lệnh ở trên, `coladderdropper` và `mlpclassifier` là tên của 2 bước trong `full_pipeline` (2 bước nào thì chắc bạn cũng đoán được). Nếu bạn tạo pipeline bằng `make_pipeline` thì tên của các bước sẽ được tự động lấy là tên của các class và được viết thường như 2 tên ở trên. Còn nếu bạn dùng `Pipeline` và tự đặt tên cho các bước thì bạn dùng tên của bạn trong phương thức `set_params`.  \n",
    "\n",
    "Như vậy, tổng cộng bạn sẽ thử nghiệm $5\\times6 = 30$ mô hình khác nhau, với mỗi mô hình bạn sẽ: huấn luyện trên tập huấn luyện, tính độ lỗi trên tập huấn luyện và tập validation rồi `append` độ lỗi vào 2 list tương ứng là `train_errs` và `var_errs` (để dễ nhìn, bạn tính độ lỗi theo đơn vị %, nghĩa là có giá trị từ 0-100 chứ không phải từ 0-1). Bạn lưu lại độ lỗi nhỏ nhất trên tập validation và giá trị `alpha` và `num_top_titles` tương ứng lần lượt vào biến `best_val_err`, `best_alpha`, `best_num_top_titles`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2bd80a2cced2a1fc2df2376226647d91",
     "grade": false,
     "grade_id": "cell-fdd12a79fb590313",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tạo full pipeline\n",
    "nume_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "cate_cols = ['Sex', 'Embarked', 'Title']\n",
    "coladderdropper = ColAdderDropper()\n",
    "imp_mean = SimpleImputer(strategy='mean')\n",
    "imp_mode = SimpleImputer(strategy='most_frequent')\n",
    "encoding = OneHotEncoder()\n",
    "categorical_transformer = make_pipeline(imp_mode, encoding)\n",
    "\n",
    "colTransform = ColumnTransformer(transformers=[('numerical', imp_mean, nume_cols),\\\n",
    "                                               ('categorical', categorical_transformer, cate_cols)])\n",
    "colNormalize = StandardScaler()\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "mlpclassifier = MLPClassifier(hidden_layer_sizes=(20), activation='tanh', solver='lbfgs', random_state=0, max_iter=500)\n",
    "full_pipeline = make_pipeline(coladderdropper, colTransform, colNormalize, mlpclassifier)\n",
    "\n",
    "# Thử nghiệm với các giá trị khác nhau của các siêu tham số\n",
    "# và chọn ra các giá trị tốt nhất\n",
    "train_errs = []\n",
    "val_errs = []\n",
    "alphas = [0.1, 1, 10, 100, 1000]\n",
    "num_top_titles_s = [1, 3, 5, 7, 9, 11]\n",
    "best_val_err = float('inf'); best_alpha = None; best_num_top_titles = None\n",
    "for alpha in alphas:\n",
    "    for num_top_titles in num_top_titles_s:\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "        full_pipeline.set_params(coladderdropper__num_top_titles=num_top_titles, mlpclassifier__alpha=alpha)\n",
    "        full_pipeline.fit(train_X_df, train_y_sr)\n",
    "        full_pipeline.predict(val_X_df)\n",
    "        train_score = full_pipeline.score(train_X_df, train_y_sr)\n",
    "        val_score = full_pipeline.score(val_X_df, val_y_sr)\n",
    "        train_err, val_err = (1 - train_score) * 100, (1 - val_score) * 100\n",
    "        train_errs.append(train_err)\n",
    "        val_errs.append(val_err)\n",
    "        if best_val_err > val_err:\n",
    "            best_val_err = val_err\n",
    "            best_alpha = alpha\n",
    "            best_num_top_titles = num_top_titles\n",
    "'Finish!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f33688c1c8f4b1a71567209f5872b5e7",
     "grade": true,
     "grade_id": "cell-0b98eab69b5f1ff7",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert round(best_val_err, 3) == 16.045\n",
    "assert best_alpha == 10\n",
    "assert best_num_top_titles == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trực quan hóa kết quả\n",
    "train_errs_df = pd.DataFrame(data=np.array(train_errs).reshape(len(alphas), -1),\n",
    "                             index=alphas, columns=num_top_titles_s)\n",
    "val_errs_df = pd.DataFrame(data=np.array(val_errs).reshape(len(alphas), -1), \n",
    "                           index=alphas, columns=num_top_titles_s)\n",
    "min_err = min(min(train_errs), min(val_errs))\n",
    "max_err = max(max(train_errs), max(val_errs))\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(train_errs_df, vmin=min_err, vmax=max_err, square=True, annot=True, \n",
    "            cbar=False, fmt='.1f', cmap='Reds')\n",
    "plt.title('train errors'); plt.xlabel('num_top_titles'); plt.ylabel('alpha')\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(val_errs_df, vmin=min_err, vmax=max_err, square=True, annot=True, \n",
    "            cbar=False, fmt='.1f', cmap='Reds')\n",
    "plt.title('validation errors'); plt.xlabel('num_top_titles'); plt.ylabel('alpha');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Nhận xét về ảnh hưởng của siêu tham số `alpha` (có sao thì bạn nói vậy, chỗ nào không biết thì nói là không biết): \n",
    "- Bạn kỳ vọng khi `alpha` thay đổi thì độ lỗi trên tập huấn luyện và tập validation sẽ thay đổi như thế nào? Tại sao bạn lại kỳ vọng như vậy?\n",
    "- Kết quả ở trên có giống như kỳ vọng của bạn không? Nếu không thì bạn nghĩ xem tại sao lại như vậy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e0471605e1a0872e36754fa0f485aa1",
     "grade": true,
     "grade_id": "cell-4debcfe69b8e605b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Nhận xét về ảnh hưởng của siêu tham số `num_top_titles` (có sao thì bạn nói vậy, chỗ nào không biết thì nói là không biết): \n",
    "- Bạn kỳ vọng khi `num_top_titles` thay đổi thì độ lỗi trên tập huấn luyện và tập validation sẽ thay đổi như thế nào? Tại sao bạn lại kỳ vọng như vậy?\n",
    "- Kết quả ở trên có giống như kỳ vọng của bạn không? Nếu không thì bạn nghĩ xem tại sao lại như vậy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49982bae0349935c9ca94046bf830735",
     "grade": true,
     "grade_id": "cell-94737f293bd3c2a8",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuối cùng, bạn sẽ huấn luyện lại `full_pipeline` trên `X_df` và `y_sr` (tập huấn luyện + tập validation) với `best_alpha` và `best_num_top_titles` tìm được ở trên để ra được mô hình cụ thể cuối cùng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e771c0641435719860146ab39be71ef8",
     "grade": true,
     "grade_id": "cell-34157b0f98b9d3f5",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "full_pipeline.set_params(coladderdropper__num_top_titles=best_num_top_titles, mlpclassifier__alpha=best_alpha)\n",
    "full_pipeline.fit(X_df, y_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Đi thi (1đ)\n",
    "Bạn sẽ dùng mô hình cụ thể cuối cùng ở trên để dự đoán với các input trong tập test (file \"test.csv\") và submit kết quả dự đoán lên Kaggle. Để có thể submit thì bạn phải tạo ra file csv có 2 cột: cột thứ nhất là id của các hành khách trong tập test, cột thứ hai là giá trị dự đoán của bạn (1 - sống, và 0 - chết). Bạn có thể xem file mẫu `submission.csv` mà mình đính kèm. Bạn đặt tên file của bạn là `my_preds.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "226b0f0ebb7e79c2866d02164cec9e2d",
     "grade": false,
     "grade_id": "cell-e184d7a3003ba334",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "test_df = pd.read_csv('test.csv', index_col=0)\n",
    "y_test = full_pipeline.predict(test_df)\n",
    "df = pd.DataFrame({test_df.index.name: test_df.index, 'Survived': y_test})\n",
    "df.to_csv('my_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7153904605d4dfe846e61beb8b47260",
     "grade": true,
     "grade_id": "cell-dbdc218117501513",
     "locked": true,
     "points": 0.75,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "my_preds_df = pd.read_csv('my_preds.csv', index_col=0)\n",
    "assert round(my_preds_df['Survived'].mean(), 3) == 0.361\n",
    "assert np.all(my_preds_df.iloc[:5].values.reshape(-1) == np.array([0, 0, 0, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Kế đến, bạn sẽ submit file csv chứa kết quả dự đoán lên [Kaggle](https://www.kaggle.com/c/titanic) (bạn sẽ cần tạo một account trên Kaggle), và ghi nhận lại độ lỗi trên tập test ở cell phía dưới."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b369b7d7c79e9110cb16f28db1c29ef0",
     "grade": true,
     "grade_id": "cell-0a8a2d0f116f035d",
     "locked": false,
     "points": 0.25,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "21.053%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
